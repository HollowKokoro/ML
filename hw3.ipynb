{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "</center>\n",
    "Авторы материала: аспирант Мехмата МГУ Евгений Колмаков, программист-исследователь Mail.ru Group Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Домашнее задание № 3. Опциональная часть \n",
    "## <center> Реализация алгоритма построения дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import sklearn.datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируем заранее `random_state` (a.k.a. random seed). Это должно повысить вероятность полной воспроизводимости результатов, впрочем, замечено, что тем не менее небольшие флуктуации возможны (например, качества прогнозов дерева, которое мы сейчас вырастим) в случае разных ОС."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Необходимо реализовать класс `DecisionTree`\n",
    "\n",
    "Спецификация:\n",
    "- класс наследуется от `sklearn.BaseEstimator`;\n",
    "- конструктор содержит следующие параметры: \n",
    "    `max_depth` - максимальная глубина дерева (по умолчанию - `numpy.inf`); \n",
    "    `min_samples_split` - минимальное число объектов в вершине, при котором происходит её разбиение (по умолчанию - 2); \n",
    "    `criterion` - критерий разбиения (для классификации - 'gini' или 'entropy', для регрессии - 'variance' или 'mad_median'; \n",
    "    по умолчанию - 'gini');\n",
    "    \n",
    "    Функционал, значение которого максимизируется для поиска оптимального разбиения в данной вершине имеет вид\n",
    "    $$Q(X, j, t) = F(X) - \\dfrac{|X_l|}{|X|} F(X_l) - \\dfrac{|X_r|}{|X|} F(X_r),$$\n",
    "    где $X$ - выборка, находящаяся в текущей вершине, $X_l$ и $X_r$ - разбиение выборки $X$ на две части \n",
    "    по предикату $[x_j < t]$, а $F(X)$ -критерий разбиения.\n",
    "    \n",
    "    Для классификации: пусть $p_i$ - доля объектов $i$-го класса в выборке $X$.\n",
    "    \n",
    "    'gini': Неопределенность Джини $F(X) = 1 -\\sum_{i = 1}^K p_i^2$.\n",
    "    \n",
    "    'entropy': Энтропия $F(X) = -\\sum_{i = 1}^K p_i \\log_2(p_i)$.\n",
    "    \n",
    "    Для регрессии: $y_j = y(x_j)$ - ответ на объекте $x_j$, $y = (y_1, \\dots, y_{|X|})$ - вектор ответов.\n",
    "    \n",
    "    'variance': Дисперсия (среднее квадратичное отклонение от среднего) $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}(y_j - \\dfrac{1}{|X|}\\sum_{x_i \\in X}y_i)^2$\n",
    "    \n",
    "    'mad_median': Среднее отклонение от медианы $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}|y_j - \\mathrm{med}(y)|$\n",
    "    \n",
    "- класс имеет методы `fit`, `predict` и `predict_proba`;\n",
    "- метод `fit` принимает матрицу объектов `X` и вектор ответов `y` (объекты `numpy.ndarray`) и возвращает экземпляр класса\n",
    "    `DecisionTree`, представляющий собой решающее дерево, обученное по выборке `(X, y)` с учётом заданных в конструкторе параметров; \n",
    "- метод `predict_proba` принимает матрицу объектов `X` и возвращает матрицу `P` размера `X.shape[0] x K`, где `K` - число классов, такую что $p_{ij}$ есть вероятность принадлежности объекта, заданного $i$-ой строкой матрицы X к классу $j \\in \\{1, \\dots, K\\}$.\n",
    "- метод `predict` принимает матрицу объектов и возвращает вектор предсказанных ответов; в случае классификации - это \n",
    "    наиболее многочисленный класс в листе, в который попал объект, а в случае регрессии - среднее значение ответов по \n",
    "    всем объектам этого листа;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    P = [len(y[y==k]) / len(y) for k in np.unique(y)]\n",
    "    return -1 * np.dot(P, np.log2(P))\n",
    "\n",
    "def gini(y):\n",
    "    P = [len(y[y==k]) / len(y) for k in np.unique(y)]\n",
    "    return 1 - np.dot(P, P)\n",
    "\n",
    "# Regression criterion functions\n",
    "def variance(y):\n",
    "    return np.var(y)\n",
    "\n",
    "def mad_median(y):\n",
    "    return np.mean(np.abs(y-np.median(y)))\n",
    "\n",
    "# Dictionary for easy mapping with input string\n",
    "criterion_dict = {'entropy': entropy,\n",
    "                  'gini': gini,\n",
    "                  'mse': variance,\n",
    "                  'mad_median' : mad_median}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "# Target prediction functions\n",
    "\n",
    "# the most popular class in leaf\n",
    "def classification_leaf(y):\n",
    "    return np.bincount(y).argmax()\n",
    "\n",
    "# the mean of all values in a leaf\n",
    "def regression_leaf(y):\n",
    "    return np.mean(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Node():\n",
    "\n",
    "    def __init__(self, feature_idx=0, threshold=0, labels=None, left=None, right=None):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.threshold = threshold\n",
    "        self.labels = labels\n",
    "        self.left = left\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(BaseEstimator):\n",
    "\n",
    "    def __init__(self,\n",
    "                 max_depth:int=np.inf,\n",
    "                 min_samples_split:int=2,\n",
    "                 criterion='gini',\n",
    "                 debug:bool=False):\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.debug = debug\n",
    "\n",
    "        self._criterion_fun = criterion_dict[self.criterion]\n",
    "\n",
    "        if self.criterion in ['mse', 'mad_median']:\n",
    "            self._leaf_value = regression_leaf\n",
    "        else:\n",
    "            self._leaf_value = classification_leaf\n",
    "\n",
    "        if debug:\n",
    "            print(\"DecisionTree\")\n",
    "            print(f\"max_depth: {self.max_depth}, min_samples_split: {self.min_samples_split}, \\\n",
    "                  criterion: {self.criterion}, debug: {self.debug}\")\n",
    "\n",
    "    # A functional returns the gain achieved if we split the data at given feature and threshold value\n",
    "    #\n",
    "    def _functional(self, X, y, feature_idx, threshold):\n",
    "        if threshold is np.nan:\n",
    "            return 0\n",
    "\n",
    "        mask = X[:,feature_idx] < threshold\n",
    "        X_l = X[ mask ]\n",
    "        y_l = y[ mask ]\n",
    "\n",
    "        X_r = X[ ~mask ]\n",
    "        y_r = y[ ~mask ]\n",
    "\n",
    "        # if all the data goes to one of the child\n",
    "        if len(X_l) == 0 or len(X_r) == 0:\n",
    "            return 0\n",
    "\n",
    "        return self._criterion_fun(y) - (X_l.shape[0]/X.shape[0])* self._criterion_fun(y_l) - (X_r.shape[0]/X.shape[0])* self._criterion_fun(y_r)\n",
    "\n",
    "\n",
    "    # recursive function to split the data and form nodes\n",
    "    #\n",
    "    def _build_tree(self, X, y, depth = 1):\n",
    "\n",
    "        # We already reached to the max_depth, so time to leave recursion\n",
    "        # by creating a leaf Node\n",
    "        if depth > self.max_depth:\n",
    "            return Node(labels=y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # We do not have sufficient samples to split\n",
    "        if n_samples < self.min_samples_split:\n",
    "            return Node(labels=y)\n",
    "\n",
    "        # If all objects in a current vertex have the same values in answers\n",
    "        # then the value of the functional will be 0 for all partitions.\n",
    "        # So in this case the vertex is a leaf. In order not to make unnecessary calculations,\n",
    "        # perform this check before the main cycle.\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return Node(labels=y)\n",
    "\n",
    "        # Here we are trying to split the data such that we will have maximun\n",
    "        # gain out of split.\n",
    "        # We will simulate the split for each unique value of each feature and\n",
    "        # calculate the functional gain. On evey account of finding the maximum gain\n",
    "        # from the previous we will keep storing the feature index and threshold value\n",
    "        # which gave this gain.\n",
    "        # At the end of this search we will have the best feature index and threshold\n",
    "        # value we should use to split the data into left and right nodes.\n",
    "        max_gain = 0\n",
    "        best_feat_idx = 0\n",
    "        best_threshold = 0\n",
    "\n",
    "        for feature_idx in range(n_features):\n",
    "            all_thresholds = np.unique(X[:,feature_idx])\n",
    "\n",
    "            all_gain = [self._functional(X, y, feature_idx, threshold) for threshold in all_thresholds]\n",
    "\n",
    "            threshold_idx = np.nanargmax(all_gain)\n",
    "\n",
    "            if all_gain[threshold_idx] > max_gain:\n",
    "                max_gain = all_gain[threshold_idx]\n",
    "                best_feat_idx = feature_idx\n",
    "                best_threshold = all_thresholds[threshold_idx]\n",
    "\n",
    "        # Split data at this best feature and threshold\n",
    "        mask = X[:,best_feat_idx] < best_threshold\n",
    "\n",
    "        return Node(best_feat_idx, best_threshold, labels=None, # We need to cache labels only at leaf node\n",
    "                    left = self._build_tree(X[mask], y[mask], depth+1), # continue to build on left side\n",
    "                    right = self._build_tree(X[~mask], y[~mask], depth+1)) # continue to build on right side\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''the method takes the matrix of instances X and a target vector y (numpy.ndarray objects)\n",
    "        and returns an instance of the class DecisionTree representing the decision tree trained on the\n",
    "        dataset (X, y) according to parameters set in the constructor'''\n",
    "\n",
    "        # remember the number classes for classification task\n",
    "        if self.criterion in ['gini', 'entropy']:\n",
    "            self._n_classes = len(np.unique(y))\n",
    "\n",
    "        self.root = self._build_tree(X, y)\n",
    "        return self\n",
    "\n",
    "\n",
    "    # predict only for one object\n",
    "    def _predict_object(self, x):\n",
    "        # Traverse from root to leaf node\n",
    "        node = self.root\n",
    "\n",
    "        while node.labels is None:\n",
    "            node = node.left if x[node.feature_idx] < node.threshold else node.right\n",
    "\n",
    "        # calculate the prediction\n",
    "        return self._leaf_value(node.labels)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''the method takes the matrix of instances X and returns a prediction vector;\n",
    "        in case of classification, prediction for an instance  xi  falling into leaf L will be the class,\n",
    "        mostly represented among instances in  L .\n",
    "        In case of regression, it will be the mean value of targets for all instances in leaf  L'''\n",
    "        return np.array([self._predict_object(x) for x in X])\n",
    "\n",
    "\n",
    "    def _predict_prob_object(self, x):\n",
    "        node = self.root\n",
    "\n",
    "        while node.labels is None:\n",
    "            node = node.left if x[node.feature_idx] < node.threshold else node.right\n",
    "\n",
    "        # calculate the probability of each class\n",
    "        # i.e number of labels of class k / total number of labels\n",
    "        return [len( node.labels[node.labels == k] ) / len(node.labels)\n",
    "                for k in range(self._n_classes)]\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        '''the method takes the matrix of instances X and returns the matrix P of a size [X.shape[0] x K],\n",
    "        where K is the number of classes and  Pij  is the probability of an instance in  i -th row of X\n",
    "        to belong to class  j∈{1,…,K}'''\n",
    "        return np.array([self._predict_prob_object(x) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестирование реализованного алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `load_digits` загрузите датасет `digits`. Разделите выборку на обучающую и тестовую с помощью метода `train_test_split`, используйте значения параметров `test_size=0.2`, `random_state=17`. Попробуйте обучить неглубокие решающие деревья и убедитесь, что критерии gini и entropy дают разные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "print(digits.data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=RANDOM_STATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.49 s, sys: 8.89 ms, total: 5.5 s\n",
      "Wall time: 5.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "DecisionTree(max_depth=100)"
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTree(max_depth=100)\n",
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        34\n",
      "           1       0.89      0.74      0.81        34\n",
      "           2       0.88      0.82      0.85        34\n",
      "           3       0.82      0.71      0.76        38\n",
      "           4       0.89      0.82      0.86        40\n",
      "           5       0.89      0.95      0.92        41\n",
      "           6       0.88      0.88      0.88        32\n",
      "           7       0.76      0.90      0.82        31\n",
      "           8       0.68      0.75      0.71        36\n",
      "           9       0.72      0.78      0.75        40\n",
      "\n",
      "    accuracy                           0.83       360\n",
      "   macro avg       0.83      0.83      0.83       360\n",
      "weighted avg       0.83      0.83      0.83       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью 5-кратной кросс-валидации (`GridSearchCV`) подберите оптимальное значение параметров `max_depth` и `criterion`. Для параметра `max_depth` используйте диапазон значений - range(3, 11), а для criterion - {'gini', 'entropy'}. Критерий качества `scoring`='accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "({'criterion': 'entropy', 'max_depth': 9}, 0.8434306039488966)"
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = 5\n",
    "\n",
    "tree_params = {'max_depth': range(3,11),\n",
    "               'criterion':['entropy', 'gini']}\n",
    "\n",
    "model = DecisionTree()\n",
    "tree_grid = GridSearchCV(model, tree_params, scoring='accuracy', n_jobs=-1, cv=kfold, verbose=True)\n",
    "tree_grid.fit(X_train, y_train)\n",
    "\n",
    "tree_grid.best_params_,tree_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96        34\n",
      "           1       0.97      0.82      0.89        34\n",
      "           2       0.83      0.88      0.86        34\n",
      "           3       0.90      0.74      0.81        38\n",
      "           4       0.80      0.93      0.86        40\n",
      "           5       0.89      0.95      0.92        41\n",
      "           6       0.93      0.84      0.89        32\n",
      "           7       0.88      0.97      0.92        31\n",
      "           8       0.82      0.86      0.84        36\n",
      "           9       0.90      0.90      0.90        40\n",
      "\n",
      "    accuracy                           0.88       360\n",
      "   macro avg       0.89      0.88      0.88       360\n",
      "weighted avg       0.89      0.88      0.88       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tree_grid.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики средних значений критерия качества `accuracy` для критериев `gini` и `entropy` в зависимости от `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame(tree_grid.cv_results_['params'])\n",
    "df_plot['accuracy'] = tree_grid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = df_plot.max_depth.sort_values().unique()\n",
    "entropy = df_plot[df_plot.criterion=='entropy'].sort_values('max_depth').accuracy\n",
    "gini = df_plot[df_plot.criterion=='gini'].sort_values('max_depth').accuracy\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, entropy, width, label='entropy')\n",
    "rects2 = ax.bar(x + width/2, gini, width, label='gini')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title('Accuracy score')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите верные утверждения:\n",
    "1. Оптимальное значение `max_depth` для каждого критерия достигается на отрезке [4, 9].\n",
    "2. На отрезке [3, 10] построенные графики не пересекаются.\n",
    "3. На отрезке [3, 10] построенные графики пересекаются ровно один раз.\n",
    "4. Наилучшее качество при `max_depth` на интервале [3, 10] достигается при использовании критерия `gini`.\n",
    "5. Хотя бы для одного из критериев значение accuracy строго возрастает с ростом значения `max_depth` на интервале [3, 10]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ:\n",
    "1. Оптимальное значение max_depth для каждого критерия достигается на отрезке [4, 9] (tree_grid.best_params_ =  'max_depth': 8)\n",
    "2. На отрезке [3, 10] построенные графики не пересекаются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чему равны найденные оптимальные значения параметров max_depth и criterion?\n",
    "1. max_depth = 7, criterion = 'gini';\n",
    "2. max_depth = 7, criterion = 'entropy';\n",
    "3. max_depth = 10, criterion = 'entropy';\n",
    "4. max_depth = 10, criterion = 'gini';\n",
    "5. max_depth = 9, criterion = 'entropy';\n",
    "6. max_depth = 9, criterion = 'gini';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ:\n",
    "ни один из перечисленных\n",
    "max_depth = 8, criterion = 'entropy';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя найденные оптимальные значения max_depth и criterion, обучите решающее дерево на X_train, y_train и вычислите вероятности принадлежности к классам для X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTree(criterion='entropy', max_depth=8)"
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(y):\n",
    "    P = [len(y[y==k]) / len(y) for k in np.unique(y)]\n",
    "    return -1 * np.dot(P, np.log2(P))\n",
    "\n",
    "model = DecisionTree(max_depth=8, criterion='entropy')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полученной матрицы вычислите усредненные по всем объектам из `X_test` значения вероятностей принадлежности к классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1"
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(model.predict_proba(X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопрос: Чему примерно равна максимальная вероятность в полученном векторе?\n",
    "1. 0.127\n",
    "2. 0.118\n",
    "3. 1.0\n",
    "4. 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ответ: 0.09"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [
    {
     "data": {
      "text/plain": "2.29128784747792"
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.array([1,2,3,4,5,6,7,8]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9938079899999066"
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.array([1,2,1,2,3,4,2,1,1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [],
   "source": [
    "class DecisionTreeReg(BaseEstimator):\n",
    "\n",
    "    def __init__(self, max_depth=np.inf, min_samples_split=2, criterion='variance', debug=False):\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.__max_depth_cnt__ = 0\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.debug = debug\n",
    "        self.criterion = criterion\n",
    "        self.__node__ = Node()\n",
    "\n",
    "    def __calculation_information__(self, y):\n",
    "        if self.criterion == 'variance':\n",
    "            return variance(y)\n",
    "        elif self.criterion == 'mad_median':\n",
    "            return mad_median(y)\n",
    "\n",
    "    def __split__(self, arr, cond):\n",
    "        return (arr[cond], arr[~cond])\n",
    "\n",
    "\n",
    "    def __information_gain__(self, information, left, right):\n",
    "        base = left.shape[0] + right.shape[0]\n",
    "        return information-(\n",
    "                ((left.shape[0]/base)*self.__calculation_information__(left))+((right.shape[0]/base)*self.__calculation_information__(right)))\n",
    "\n",
    "    def __build_tree__(self, tree, X, y, depth_cnt):\n",
    "\n",
    "        tree.values_pred = copy.deepcopy(y)\n",
    "\n",
    "        tree.information = self.__calculation_information__(y)\n",
    "\n",
    "        if self.max_depth == depth_cnt:\n",
    "            return\n",
    "\n",
    "        depth_cnt+=1\n",
    "        tree.depth = copy.deepcopy(depth_cnt)\n",
    "\n",
    "        if tree.information == 0:\n",
    "            return\n",
    "\n",
    "        if self.min_samples_split >= X.shape[0]:\n",
    "            return\n",
    "\n",
    "        x = np.column_stack((X, y.reshape((-1, 1))[:, 0]))\n",
    "\n",
    "        best_gain = 0\n",
    "        best_feature = 0\n",
    "        best_val = None\n",
    "\n",
    "        for feature in range(x.shape[1]-1):\n",
    "            for val in np.unique(x[:,feature]):\n",
    "                (left, right) = self.__split__(x,x[:,feature]<val)\n",
    "\n",
    "                if left[:,-1].shape[0]!=0 and right[:,-1].shape[0]!=0:\n",
    "                    next_gain = self.__information_gain__(tree.information, left[:,-1], right[:,-1])\n",
    "                    if best_gain < next_gain:\n",
    "                        best_gain = copy.deepcopy(next_gain)\n",
    "                        best_feature = copy.deepcopy(feature)\n",
    "                        best_val = copy.deepcopy(val)\n",
    "\n",
    "        if best_val is None:\n",
    "            best_val = np.median(x[:,best_feature])\n",
    "\n",
    "        tree.splitting_feature = copy.deepcopy(best_feature)\n",
    "        tree.splitting_values = copy.deepcopy(best_val)\n",
    "\n",
    "        (left, right) = self.__split__(x,x[:,best_feature]<best_val)\n",
    "\n",
    "        tree.left = Node()\n",
    "        self.__build_tree__(tree=tree.left, X=left[:,:-1], y=left[:,-1], depth_cnt=tree.depth)\n",
    "\n",
    "        tree.right = Node()\n",
    "        self.__build_tree__(tree=tree.right, X=right[:,:-1], y=right[:,-1], depth_cnt=tree.depth)\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.__build_tree__(tree=self.__node__, X=X, y=y, depth_cnt=self.__max_depth_cnt__)\n",
    "\n",
    "\n",
    "    def __predict_tree__(self, tree, x):\n",
    "\n",
    "        if tree.right is None and tree.left is None:\n",
    "            return tree.values_pred\n",
    "\n",
    "        if x[tree.splitting_feature]<tree.splitting_values:\n",
    "            if tree.left is None:\n",
    "                return tree.values_pred\n",
    "            return self.__predict_tree__(tree.left, x)\n",
    "\n",
    "        else:\n",
    "            if tree.right is None:\n",
    "                return tree.values_pred\n",
    "            return self.__predict_tree__(tree.right, x)\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = []\n",
    "        for i in X:\n",
    "            y = self.__predict_tree__(self.__node__, i)\n",
    "            pred.append(np.mean(y))\n",
    "        return np.array(pred)\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return mean_squared_error(y, self.predict(X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this case special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows:\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and:\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston  = sklearn.datasets.load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "data": {
      "text/plain": "11.382647058823528"
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeReg(criterion='variance')\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = DecisionTreeReg(criterion='mad_median')\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 298,
   "outputs": [
    {
     "data": {
      "text/plain": "15.262622549019609"
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "С помощью 5-кратной кросс-валидации подберите оптимальное значение параметров `max_depth` и `criterion`. Для параметра `max_depth` используйте диапазон значений - `range(2, 9)`, а для `criterion` - {'variance', 'mad_median'}. Критерий качества `scoring`='neg_mean_squared_error'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "({'criterion': 'mad_median', 'max_depth': 4}, -21.157004600133206)"
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = 5\n",
    "\n",
    "tree_params = {'max_depth': range(2,9),\n",
    "               'criterion':['variance', 'mad_median']}\n",
    "\n",
    "model = DecisionTreeReg()\n",
    "tree_grid = GridSearchCV(model, tree_params, scoring='neg_mean_squared_error', cv=kfold, n_jobs=-1, verbose=True)\n",
    "tree_grid.fit(X_train, y_train)\n",
    "\n",
    "tree_grid.best_params_,tree_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Постройте графики средних значений критерия качества `neg_mean_squared_error` для критериев `variance` и `mad_median` в зависимости от `max_depth`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame(tree_grid.cv_results_['params'])\n",
    "df_plot['accuracy'] = tree_grid.cv_results_['mean_test_score']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = df_plot.max_depth.sort_values().unique()\n",
    "variance = df_plot[df_plot.criterion=='variance'].sort_values('max_depth').accuracy\n",
    "mad_median = df_plot[df_plot.criterion=='mad_median'].sort_values('max_depth').accuracy\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, variance, width, label='variance')\n",
    "rects2 = ax.bar(x + width/2, mad_median, width, label='mad_median')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Neg_mean_squared_error')\n",
    "ax.set_xlabel('max_depth')\n",
    "ax.set_title('Neg_mean_squared_error score')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите верные утверждения:\n",
    "1. На отрезке [2, 8] построенные графики не пересекаются.\n",
    "2. На отрезке [2, 8] построенные графики пересекаются ровно один раз.\n",
    "3. Оптимальное значение `max_depth` для каждого из критериев достигается на границе отрезка [2, 8].\n",
    "4. Наилучшее качество при `max_depth` из [2, 8] достигается при использовании критерия `mad_median`."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ответ:\n",
    "3. Оптимальное значение max_depth для каждого из критериев достигается на границе отрезка [2, 8].\n",
    "4. Наилучшее качество при max_depth из [2, 8] достигается при использовании критерия mad_median."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чему равны найденные оптимальные значения параметров `max_depth` и `criterion`?\n",
    "1. max_depth = 9, criterion = 'variance';\n",
    "2. max_depth = 5, criterion = 'mad_median';\n",
    "3. max_depth = 4, criterion = 'variance';\n",
    "4. max_depth = 2, criterion = 'mad_median';\n",
    "5. max_depth = 4, criterion = 'mad_median';\n",
    "6. max_depth = 5, criterion = 'variance';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "name": "lesson4_part2_Decision_trees.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}